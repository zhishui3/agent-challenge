# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "openai",
# ]
# ///

import os
import json
import sys
import time
from openai import OpenAI

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
API_KEY = os.getenv("DEEPSEEK_API_KEY")
BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
# å…è®¸ä»ç¯å¢ƒå˜é‡è¦†ç›–æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º deepseek-chat
MODEL_NAME = os.getenv("DEEPSEEK_MODEL_NAME", "deepseek-chat")

if not API_KEY:
    print("âŒ Error: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
    sys.exit(1)

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

class LongArticleAgent:
    def __init__(self, topic):
        self.topic = topic
        self.outline = []
        self.articles = []

    def step1_generate_outline(self):
        """Step 1: ç”Ÿæˆç« èŠ‚å¤§çº²"""
        print(f"ğŸ“‹ æ­£åœ¨è§„åˆ’ä¸»é¢˜: {self.topic}...")
        
        # TODO: ç¼–å†™ Prompt è®©æ¨¡å‹ç”Ÿæˆçº¯ JSON åˆ—è¡¨
        prompt = f"è¯·ä¸ºä¸»é¢˜ã€Š{self.topic}ã€‹ç”Ÿæˆä¸€ä¸ªåŒ…å«3ä¸ªç« èŠ‚çš„å¤§çº²..."+"""
        
        è¦æ±‚ï¼š
        1. è¾“å‡ºå¿…é¡»æ˜¯çº¯JSONæ ¼å¼ï¼Œä¸åŒ…å«ä»»ä½•Markdownæ ‡è®°æˆ–é¢å¤–è§£é‡Š[2](@ref)
        2. åŒ…å«3ä¸ªä¸»è¦ç« èŠ‚ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å«æ ‡é¢˜å’Œ1-3ä¸ªå…³é”®è¦ç‚¹
        3. ç« èŠ‚ä¹‹é—´è¦æœ‰é€»è¾‘é€’è¿›å…³ç³»
        
        ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
        {{
            "outline": [
                {{
                    "title": "ç« èŠ‚æ ‡é¢˜1",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "title": "ç« èŠ‚æ ‡é¢˜2", 
                    "key_points": ["è¦ç‚¹1"]
                }},
                {{
                    "title": "ç« èŠ‚æ ‡é¢˜3",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2"]
                }}
            ]
        }}
        
        åªè¾“å‡ºJSONå¯¹è±¡ï¼Œä¸è¦å…¶ä»–ä»»ä½•å†…å®¹ã€‚
        """
        
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œè§„åˆ’å¸ˆï¼Œåªè¾“å‡º JSON Arrayã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7
            )
            content = response.choices[0].message.content
            
            # TODO: è§£æè¿”å›çš„ JSON å†…å®¹åˆ° self.outline
            data = json.loads(content)
            
            # ç®€å•çš„å®¹é”™é€»è¾‘ç¤ºä¾‹ï¼ˆå€™é€‰äººéœ€è¦å®Œå–„ï¼‰
            # if isinstance(data, list):
            #     self.outline = data
            # elif isinstance(data, dict):
            #     for key, value in data.items():
            #         if isinstance(value, list):
            #             self.outline = value
            #             break
            if "outline" in data and isinstance(data["outline"], list):
                self.outline = data["outline"]
            elif isinstance(data, list):
                # å¦‚æœç›´æ¥è¿”å›æ•°ç»„
                self.outline = [{"title": item, "key_points": []} if isinstance(item, str) else item for item in data]
            else:
                # å°è¯•æŸ¥æ‰¾ä»»ä½•åŒ…å«ç« èŠ‚ä¿¡æ¯çš„é”®
                for key, value in data.items():
                    if isinstance(value, list) and len(value) > 0:
                        if isinstance(value[0], dict) and "title" in value[0]:
                            self.outline = value
                            break
                        elif isinstance(value[0], str):
                            self.outline = [{"title": title, "key_points": []} for title in value]
                            break
            if not self.outline:
                raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å¤§çº²åˆ—è¡¨")

            print(f"âœ… å¤§çº²å·²ç”Ÿæˆ: {self.outline}")

        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            print(f"Raw Content: {content if 'content' in locals() else 'None'}")
            sys.exit(1)

    def step2_generate_content_loop(self):
        """Step 2: å¾ªç¯ç”Ÿæˆå†…å®¹ï¼Œå¹¶ç»´æŠ¤ Context"""
        if not self.outline:
            return

        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ‘˜è¦
        previous_summary = "æ–‡ç« å¼€å§‹ã€‚"
        
        print("\nğŸš€ å¼€å§‹æ’°å†™æ­£æ–‡...")
        for i, chapter in enumerate(self.outline):
            print(f"[{i+1}/{len(self.outline)}] æ­£åœ¨æ’°å†™: {chapter}...")
            
            # TODO: æ„é€  Promptï¼Œæ ¸å¿ƒåœ¨äº Context çš„æ³¨å…¥
            key_points_text="æœ¬ç« éœ€è¦æ¶µç›–ä»¥ä¸‹è¦ç‚¹ï¼š\n" + "\n".join([f"- {point}" for point in chapter['key_points']])
            prompt = f"""
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šä½œå®¶ã€‚è¯·æ’°å†™ç« èŠ‚ï¼š"{chapter}"ã€‚
            
            ã€å‰æƒ…æè¦ã€‘ï¼š
            {previous_summary}
            ã€æœ¬ç« å†™ä½œè¦æ±‚ã€‘ï¼š
{key_points_text}

ã€å…·ä½“æŒ‡ä»¤ã€‘ï¼š
1. å†…å®¹å……å®ï¼Œå­—æ•°çº¦300å­—ã€‚
2. å¿…é¡»è‡ªç„¶æ‰¿æ¥ã€å‰æƒ…æè¦ã€‘çš„é€»è¾‘ï¼Œä¸è¦é‡å¤å‰æ–‡å·²è¯¦ç»†é˜è¿°çš„å†…å®¹
3. ä¿æŒä¸“ä¸šä¸”æµç•…çš„æ–‡é£ï¼Œä¸ºåç»­ç« èŠ‚åšå¥½é“ºå«
4. ç¡®ä¿é€»è¾‘è¿è´¯ï¼Œè§‚ç‚¹æ˜ç¡®ï¼Œè®ºæ®å……åˆ†

è¯·å¼€å§‹æ’°å†™æœ¬ç« å†…å®¹ï¼š

            """
            
            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                content = response.choices[0].message.content
                self.articles.append(f"## {chapter}\n\n{content}")
                
                # TODO: æ›´æ–° Context (æ ¸å¿ƒè€ƒå¯Ÿç‚¹)
                # ç®€å•ç­–ç•¥ï¼šæˆªå–æœ€å 200 å­—
                previous_summary = self._update_context_summary(
                    previous_summary, chapter['title'], content, i
                )
                # previous_summary = content[-200:]
                
            except Exception as e:
                print(f"âš ï¸ ç« èŠ‚ {chapter} ç”Ÿæˆå¤±è´¥: {e}")

    def _update_context_summary(self, current_summary, chapter_title, new_content, chapter_index):
        if chapter_index == 0:
            # ç¬¬ä¸€ç« ï¼šåŸºäºå†…å®¹ç”Ÿæˆæ‘˜è¦
            summary_prompt = f"""
            è¯·å¯¹ä»¥ä¸‹æ–‡ç« ç« èŠ‚å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ100å­—å·¦å³ï¼‰ï¼Œç”¨äºåç»­ç« èŠ‚çš„ä¸Šä¸‹æ–‡è¡”æ¥ï¼š

            ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}
            ç« èŠ‚å†…å®¹ï¼š{new_content}

            æ‘˜è¦è¦æ±‚ï¼š
            1. æå–æ ¸å¿ƒè§‚ç‚¹å’Œå…³é”®ä¿¡æ¯
            2. ä¿æŒé€»è¾‘è¿è´¯æ€§
            3. ä¸ºä¸‹ä¸€ç« åšå¥½é“ºå«

            æ‘˜è¦ï¼š
            """

            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[{"role": "user", "content": summary_prompt}],
                    temperature=0.3,
                    max_tokens=200
                )
                new_summary = response.choices[0].message.content
            except:
                # å¦‚æœæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½æˆªæ–­
                new_summary = self.truncate_context(new_content, 150)
        else:
            # åç»­ç« èŠ‚ï¼šç»“åˆç°æœ‰æ‘˜è¦å’Œæ–°å†…å®¹ç”Ÿæˆæ›´æ–°æ‘˜è¦
            update_prompt = f"""
            ç°æœ‰æ–‡ç« æ‘˜è¦ï¼š{current_summary}

            æ–°å¢ç« èŠ‚å†…å®¹ï¼š{new_content}

            è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªæ›´æ–°çš„ç»¼åˆæ‘˜è¦ï¼ˆ150å­—å·¦å³ï¼‰ï¼Œè¦æ±‚ï¼š
            1. ä¿ç•™å‰æ–‡çš„æ ¸å¿ƒä¿¡æ¯
            2. èå…¥æ–°ç« èŠ‚çš„å…³é”®å†…å®¹
            3. ä¿æŒæ•´ä½“é€»è¾‘è¿è´¯
            4. ä¸ºä¸‹ä¸€ç« åšå¥½è‡ªç„¶è¿‡æ¸¡

            æ›´æ–°åçš„æ‘˜è¦ï¼š
            """

            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[{"role": "user", "content": update_prompt}],
                    temperature=0.3,
                    max_tokens=250
                )
                new_summary = response.choices[0].message.content
            except:
                # é™çº§æ–¹æ¡ˆï¼šç»„åˆ+æˆªæ–­
                combined = f"{current_summary}\n\nã€{chapter_title}ã€‘ä¸»è¦å†…å®¹ï¼š{self.truncate_context(new_content, 100)}"
                new_summary = self.truncate_context(combined, 200)

        return new_summary

    def save_result(self):
        if not self.articles:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•å†…å®¹")
            return
            
        filename = "final_article.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"# {self.topic}\n\n")
            f.write("\n\n".join(self.articles))
        print(f"\nğŸ‰ æ–‡ç« å·²ä¿å­˜è‡³ {filename}")

if __name__ == "__main__":
    print(f"ğŸ”Œ Endpoint: {BASE_URL}")
    print(f"ğŸ§  Model: {MODEL_NAME}\n")
    
    agent = LongArticleAgent("2025å¹´ DeepSeek å¯¹ AI è¡Œä¸šçš„å½±å“")
    agent.step1_generate_outline()
    agent.step2_generate_content_loop()
    agent.save_result()
